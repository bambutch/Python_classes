{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bambutch/python_classes/blob/main/%D0%9F%D0%B0%D1%80%D1%81%D0%B8%D0%BD%D0%B3_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85_%D1%81_%D1%81%D0%B0%D0%B9%D1%82%D0%BE%D0%B2_%D0%BD%D0%B0_Python_%D1%81_%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E_%D0%B1%D0%B8%D0%B1%D0%BB%D0%B8%D0%BE%D1%82%D0%B5%D0%BA%D0%B8_BeautifulSoup(%D0%9A%D0%BD%D0%B8%D0%B3%D0%B8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Парсинг данных с сайтов на Python с помощью библиотеки BeautifulSoup\n",
        "\n"
      ],
      "metadata": {
        "id": "SA80KwzFM6kA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Библиотека BeautifulSoup"
      ],
      "metadata": {
        "id": "nXQHhQGL5srA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Документация](http://www.crummy.com/software/BeautifulSoup/)"
      ],
      "metadata": {
        "id": "zlpNdW3j51nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beautiful Soup** — это библиотека Python для извлечения данных из файлов HTML и XML. Она работает с вашим любимым парсером, чтобы дать вам естественные способы навигации, поиска и изменения дерева разбора. Она обычно экономит программистам часы и дни работы.\n"
      ],
      "metadata": {
        "id": "BRxw-Y4k5vw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установка библиотеки:\n",
        "\n",
        "```python\n",
        "!pip install bs4\n",
        "```"
      ],
      "metadata": {
        "id": "T261pize59AO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BS использует парсер, самым быстрым считается **lxml**\n",
        "<br>В стандартных библиотеках Python такой библиотеки , поэтому ее необходимо устанавливать\n",
        "```python\n",
        "!pip install lxml\n",
        "```\n",
        "\n",
        "Импортировать в код ее при этом не нужно"
      ],
      "metadata": {
        "id": "9xwrI_g06DF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3"
      ],
      "metadata": {
        "id": "Hmi0RzgZ5qBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-8auURcjU2j",
        "outputId": "e9d3a3a4-4596-44f9-8930-ff81ca2e783a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml"
      ],
      "metadata": {
        "id": "-B7uBvBWqwp9",
        "outputId": "695df94a-f2e1-48f5-8e9f-40e2b0bc48c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cVc4y31j6xdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml\n",
        "\n",
        "URL = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "\n",
        "def get_html(page):\n",
        "  \"\"\"Собирает html\"\"\"\n",
        "  # Инициализация сессии\n",
        "  session = requests.session()\n",
        "  # Указание заголовков сессии\n",
        "  session.headers = {\n",
        "      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36\",\n",
        "      \"Accept-language\": \"ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7\"\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    # Указание заголовков сессии\n",
        "    res = session.get(URL.format(page))\n",
        "    # Проверка на ошибку\n",
        "    res.raise_for_status()\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "    return\n",
        "\n",
        "  return res.text\n",
        "\n",
        "\n",
        "def get_soup(page):\n",
        "  \"\"\" Варит суп \"\"\"\n",
        "  # Получаем исходный код\n",
        "  html = get_html(page)\n",
        "  # Если нету страницы, то выходим\n",
        "  if not html: return\n",
        "  # Начинаем варить суп (Инициализируем bs)\n",
        "  soup = BeautifulSoup(html, \"lxml\")\n",
        "  return soup\n",
        "\n",
        "\n",
        "def get_book_info(li):\n",
        "  \"\"\" Собирает информацию о книге \"\"\"\n",
        "  # Получаем название книги, которое находится в теге <a> внутри <h3> \n",
        "  title = li.select_one(\"h3 a\")\n",
        "  if not title:\n",
        "    print(\"Error find title!\")\n",
        "    return\n",
        "  title = title[\"title\"]\n",
        "\n",
        "  # Получаем рейтинг книги, которое находится в теге <p> с классом \"star-rating\"\n",
        "  rating = li.select_one(\"p.star-rating\")\n",
        "  if not rating:\n",
        "    print(\"Error find rating!\")\n",
        "    return\n",
        "  rating = rating[\"class\"][1]\n",
        "\n",
        "  # Словарь, который сопостовляет слово с цифрой\n",
        "  WORD_TO_NUM = {\n",
        "      \"One\": 1,\n",
        "      \"Two\": 2,\n",
        "      \"Three\": 3,\n",
        "      \"Four\": 4,\n",
        "      \"Five\": 5\n",
        "  }\n",
        "  rating = WORD_TO_NUM.get(rating, 0)\n",
        "\n",
        "  # Получаем рейтинг книги, которое находится в теге <p> обернутым в тег\n",
        "  # <div> с классом \"product_price\"\n",
        "  price = li.select_one(\"div.product_price p\")\n",
        "  if not price:\n",
        "    print(\"Error find price!\")\n",
        "    return\n",
        "  # Получаем часть текста до знака £\n",
        "  price = price.text.split(\"£\")[1]\n",
        "\n",
        "  # Возвращаем информацию о книге\n",
        "  return {\n",
        "      \"title\": title,\n",
        "      \"rating\": rating,\n",
        "      \"price\": price\n",
        "  }\n",
        "\n",
        "def get_books_info(soup):\n",
        "  \"\"\" Информация о книгах на странице \"\"\"\n",
        "  # Получаем список книг со страницы в теге <ol> с классом \"row\"\n",
        "  list_rows = soup.select_one(\"ol.row\")\n",
        "  # Получаем карточки о книгах из списка в теге <li>\n",
        "  all_li = list_rows.select(\"li\")\n",
        "  result = []\n",
        "  # Проходимся по каждой карточке и достаем из нее информацию\n",
        "  for li in all_li:\n",
        "    result.append(get_book_info(li))\n",
        "  # Краткая запись\n",
        "  # result = [get_book_info(li) for li in all_li]\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "VxleNhb0lnya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import csv\n",
        "\n",
        "# select - все  искомые элемент\n",
        "# select_one - первый попавшийся искомый элемент\n",
        "\n",
        "# 1. Цикл по страницам\n",
        "# 2. Получить исходный код\n",
        "# 3. Сварить суп из исходного кода\n",
        "# 4. Получить информацию о книгах\n",
        "\n",
        "\n",
        "result = []\n",
        "# # Вариант с range\n",
        "# # Цикл по количеству страниц\n",
        "# for page in range(1, 3):\n",
        "#   # Перерыв между запросами\n",
        "#   time.sleep(3)\n",
        "#   soup = get_soup(page)\n",
        "#   if not soup:\n",
        "#     # Если нету супа, то выходим из цикла => либо ошибка, либо конец страниц\n",
        "#     break\n",
        "#   # Получаем информацию о книгах\n",
        "#   books_info = get_books_info(soup)\n",
        "#   # Записываем в result получившуюся инфу о книгах на странице\n",
        "#   result = result + books_info\n",
        "\n",
        "# Вариант с циклом while\n",
        "# Стартовый номер страницы\n",
        "page = 1\n",
        "# Бесконечный цикл\n",
        "while True:\n",
        "  # Перерыв между запросами\n",
        "  time.sleep(3)\n",
        "  soup = get_soup(page)\n",
        "  if not soup:\n",
        "    # Если нету супа, то выходим из цикла => либо ошибка, либо конец страниц\n",
        "    break\n",
        "  # Получаем информацию о книгах\n",
        "  books_info = get_books_info(soup)\n",
        "  # Записываем в result получившуюся инфу о книгах на странице\n",
        "  result = result + books_info\n",
        "  # Переходим на следующую страницу\n",
        "  page = page + 1\n",
        "print(f\"Всего пройдено страниц: {page-1}\")\n",
        "\n",
        "with open(\"books.csv\", \"w\") as f:\n",
        "  writer = csv.DictWriter(f, result[0].keys())\n",
        "  writer.writeheader()\n",
        "  for r in result:\n",
        "    writer.writerow(r)"
      ],
      "metadata": {
        "id": "rkrmlYzEzlGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yojr9KjBR1PG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}